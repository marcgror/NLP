{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will try to generate fake text using a RNN trained with text extracted from a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Importing necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils.data_utils import get_file\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the reproducibility of the results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading the real text, in this case the Frankensein book, which is loaded from the file 'Frankensein.txt':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "corpus length: 420636\n"
    }
   ],
   "source": [
    "# Reading the text\n",
    "path = 'Frankenstein.txt'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "# Print the text length\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print a few lines from the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "letter 1\n\n_to mrs. saville, england._\n\n\nst. petersburgh, dec. 11th, 17â€”.\n\n\nyou will rejoice to hear that no disaster has accompanied the\ncommencement of an enterprise which you have regarded with such evil\nforebodings.  i arrived here yesterday, and my first task is to assure\nmy dear sister of my welfare and increasing confidence in the success\nof my undertaking.\n\ni am already far north of london, and as i walk in the streets of\npetersburgh, i feel a cold northern breeze play upon my cheeks, whi\n"
    }
   ],
   "source": [
    "# Print a little extract from the text\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the vocabulary, a list of unique characters present on the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vocabulary from the text\n",
    "vocabulary = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To move from a character to index and the reverse way, these two dictionaries will be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character-to-index dictionary for mapping\n",
    "char_to_idx = { char : idx for idx, char in enumerate(vocabulary)}\n",
    "# Index-to-character dictionary for reverse mapping\n",
    "idx_to_char = {idx : char for idx, char in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create and fill the input and target vectors with the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and target data from raw text\n",
    "input_data = []\n",
    "target_data = []\n",
    "maxlen = 40\n",
    "for i in range(0, len(text) - maxlen):\n",
    "    input_data.append(text[i : i + maxlen])\n",
    "    target_data.append(text[i + maxlen])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors to encode input and output data\n",
    "x = np.zeros((len(input_data), maxlen, len(vocabulary)), dtype='float32')\n",
    "y = np.zeros((len(target_data), len(vocabulary)), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the encoded the vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize input and target vector\n",
    "for s_idx, sequence in enumerate(input_data):\n",
    "    for idx, char in enumerate(sequence):\n",
    "        x[s_idx, idx, char_to_idx[char]] = 1\n",
    "    y[s_idx, char_to_idx[target_data[s_idx]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 40, 128)           96768     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 40, 128)           131584    \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 128)               131584    \n_________________________________________________________________\ndense (Dense)                (None, 60)                7740      \n=================================================================\nTotal params: 367,676\nTrainable params: 367,676\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, return_sequences=True, input_shape=(maxlen, len(vocabulary))))\n",
    "model.add(keras.layers.LSTM(128, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(128))\n",
    "model.add(keras.layers.Dense(len(vocabulary), activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# View the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model  with the preprocessed text during 5 epochs (for computational reasons):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 336476 samples, validate on 84120 samples\nEpoch 1/5\n336476/336476 [==============================] - 105s 312us/sample - loss: 2.2656 - val_loss: 1.9232\nEpoch 2/5\n336476/336476 [==============================] - 99s 295us/sample - loss: 1.8135 - val_loss: 1.7344\nEpoch 3/5\n336476/336476 [==============================] - 100s 297us/sample - loss: 1.6511 - val_loss: 1.6248\nEpoch 4/5\n336476/336476 [==============================] - 101s 300us/sample - loss: 1.5480 - val_loss: 1.5493\nEpoch 5/5\n336476/336476 [==============================] - 101s 302us/sample - loss: 1.4779 - val_loss: 1.5054\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x28c69a91e88>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Fit the model to the input and target data\n",
    "model.fit(x, y, batch_size=64, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('frankenstein_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the results obtained with different number of training epochs, I trained the same model with the same real text, but for 50 epochs. This took me several hours of training, even using an old GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 40, 128)           96768     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 40, 128)           131584    \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 128)               131584    \n_________________________________________________________________\ndense (Dense)                (None, 60)                7740      \n=================================================================\nTotal params: 367,676\nTrainable params: 367,676\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Load the saved model (if needed)\n",
    "model_50 = keras.models.load_model('frankenstein_model_50_epochs.h5')\n",
    "model_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we a few sentences from the input text as seed for the text generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sentence from the input data\n",
    "start = np.random.randint(0, len(input_data) -1)\n",
    "seed = input_data[start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ious parts of the heavens. the\nmost viol\n"
    }
   ],
   "source": [
    "# Print the seed sentence\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates 'n' new characters based on the 'seed', and given the input model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generate new text\n",
    "def generate_text(model, sentence, n):\n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    model = model\n",
    "    for i in range(n):\n",
    "        # Initialize the input vector\n",
    "        X_test = np.zeros((1, maxlen, len(vocabulary)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            X_test[0, t, char_to_idx[char]] = 1\n",
    "        # Predict the output vector\n",
    "        preds = model.predict(X_test, verbose=0)[0]\n",
    "        # Character with max probability\n",
    "        next_index = np.argmax(preds)\n",
    "        # Map from index to character\n",
    "        next_char = idx_to_char[next_index]\n",
    "        # Add the new character to the sentence\n",
    "        sentence = sentence[1:] + next_char\n",
    "        # Add the new character to the generated text\n",
    "        generated += next_char\n",
    "    print(generated)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 5-epochs model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ious parts of the heavens. the\nmost violent of the stranger and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and \n"
    }
   ],
   "source": [
    "# Generate new text\n",
    "generate_text(model, seed, 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, using the model trained during 50 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ious parts of the heavens. the\nmost violent attention i had suffered to the most continual philosophers of the subject should be conceived. he had alread the stranger of the stranger, and i thought that i might be a consideration of the same subject to my father, and i then the strant misfortunes, i will not be tormented the same country of the sun distinction the subject of the same sufferings of the same time that i might over the same country in the most sense of the same country in\n"
    }
   ],
   "source": [
    "generate_text(model_50, seed, 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviusly, the text generated using the model trained during 50 epochs has a lot more sense, both in the structure and the use of verb forms. But it still being confusing on some points, and it starts to repeat the same characters at the end (the same country in the most).\n",
    "\n",
    "It can be improved then."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmyenvconda966a52bc464c4d8495af3e092d2af30f",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}